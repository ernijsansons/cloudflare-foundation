# CLAUDE CODE â€” DOC SCANNER DEPLOY

# C:\dev\.cloudflare\cloudflare-foundation-dev

#

# PASTE THIS ENTIRE FILE AS YOUR FIRST MESSAGE IN CLAUDE CODE

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

You are a senior Cloudflare platform engineer. Deploy and validate the
Cloudflare Doc Auto-Update System in this monorepo. Work autonomously.
Show every command output. Fix every error before moving on.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## GROUND TRUTH â€” EXACTLY WHAT EXISTS RIGHT NOW

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SECRETS (already set on cron Worker production):
âœ… DEEPSEEK_API_KEY â€” set via wrangler secret

D1 TABLES (already exist in foundation-primary):
âœ… doc_scan_state
âœ… doc_update_reports

MIGRATION: skip Phase 5 entirely â€” tables exist.

ANTHROPIC_API_KEY: NOT set. NOT needed on the Worker.
The Worker must work with DeepSeek ONLY (no Claude API key on the server).
The local apply script (apply-updates.mjs) will use Claude Code's built-in
subscription via the computer â€” it does NOT need ANTHROPIC_API_KEY env var.

BUGS TO FIX:
âŒ doc-scanner.ts â€” only calls Claude API, has no DeepSeek support,
will FAIL at runtime since ANTHROPIC_API_KEY not set
âŒ services/cron/src/index.ts â€” Env interface has `ANTHROPIC_API_KEY: string`
(required, non-optional) â€” deploy will break without it
âŒ apply-updates.mjs â€” DOC_ROOT resolves one level too shallow (points to
cloudflare-foundation-dev instead of cloudflare root),
exits if ANTHROPIC_API_KEY not set (wrong for our setup),
gateway URLs are /cron/... instead of /api/cron/...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## RULES

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Read every file before editing it. Never guess at current content.
2. No hardcoded secrets. Secrets already exist â€” just reference them.
3. Run `npx tsc --noEmit` after every edit. Zero errors before deploy.
4. DeepSeek is the ONLY AI provider on the Worker. No Claude fallback server-side.
5. apply-updates.mjs applies edits by calling YOU (Claude Code) directly â€” no API key needed.
6. One source failing must not crash the scanner â€” Promise.allSettled everywhere (already done).
7. Surgical edits to doc files. Never reformat unrelated sections.
8. Show every command output.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 1 â€” FIX services/cron/src/jobs/doc-scanner.ts

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Read the file first. Then make these changes:

### 1A â€” Add ScannerEnv interface (after the Finding interface)

```typescript
export interface ScannerEnv {
	DB: D1Database;
	DEEPSEEK_API_KEY?: string;
	DOC_UPDATE_WEBHOOK?: string;
}
```

### 1B â€” Replace the entire analyzeWithClaude function

Delete `analyzeWithClaude` and everything in it. Replace with:

````typescript
// â”€â”€â”€ Shared prompt builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const ANALYSIS_SYSTEM_PROMPT =
	'You are a Cloudflare documentation maintenance agent. ' +
	'Analyze release announcements and return ONLY a valid JSON array. ' +
	'No markdown fences. No explanation. No preamble. Just the JSON array.';

function buildAnalysisPrompt(newItems: ChangeItem[]): string {
	return `The following new Cloudflare releases were detected:

${newItems
	.map(
		(item, i) => `--- Item ${i + 1} ---
Source: ${item.source}
Title: ${item.title}
Published: ${item.publishedAt}
URL: ${item.url}
Description: ${item.description}`
	)
	.join('\n\n')}

Our doc files (at C:\\dev\\.cloudflare\\):
${DOC_FILES.map((f) => `- ${f}`).join('\n')}

Always update docs for: new SDK versions, new/changed APIs, new CF products,
breaking changes, deprecations, new limits, new auth flows.

Return a JSON array. Each element:
{
  "source": "source name",
  "changeTitle": "concise title",
  "changeUrl": "url",
  "publishedAt": "ISO date",
  "affectedFiles": ["BIBLE.md"],
  "suggestedAction": "Exact edit: what to change, where, and new value",
  "priority": "critical|high|medium|low"
}

Priority: critical=SDK bump/breaking, high=new feature/product,
medium=new limit/quota, low=blog/announcement only.
Omit items needing no doc changes. Return [] if nothing needs updating.`;
}

// â”€â”€â”€ DeepSeek analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function analyzeWithDeepSeek(newItems: ChangeItem[], apiKey: string): Promise<Finding[]> {
	if (newItems.length === 0) return [];

	try {
		const res = await fetch('https://api.deepseek.com/v1/chat/completions', {
			method: 'POST',
			headers: {
				'Content-Type': 'application/json',
				Authorization: `Bearer ${apiKey}`
			},
			body: JSON.stringify({
				model: 'deepseek-chat',
				max_tokens: 3000,
				temperature: 0.1,
				messages: [
					{ role: 'system', content: ANALYSIS_SYSTEM_PROMPT },
					{ role: 'user', content: buildAnalysisPrompt(newItems) }
				]
			})
		});

		if (!res.ok) {
			console.error(`DeepSeek returned HTTP ${res.status}:`, await res.text());
			return [];
		}

		const data = (await res.json()) as {
			choices: Array<{ message: { content: string } }>;
		};
		const text = data.choices?.[0]?.message?.content ?? '';
		const clean = text.replace(/```json\n?|\n?```/g, '').trim();
		const parsed = JSON.parse(clean);
		return Array.isArray(parsed) ? (parsed as Finding[]) : [];
	} catch (e) {
		console.error('DeepSeek analysis failed:', e instanceof Error ? e.message : e);
		return [];
	}
}
````

### 1C â€” Update runDocScanner signature and internal call

Change the function signature from:

```typescript
export async function runDocScanner(
  db: D1Database,
  anthropicApiKey: string
): Promise<DocUpdateReport> {
```

To:

```typescript
export async function runDocScanner(
  db: D1Database,
  env: ScannerEnv
): Promise<DocUpdateReport> {
```

Inside the function, replace:

```typescript
const findings = await analyzeWithClaude(allNewItems, anthropicApiKey);
console.log(`Claude identified ${findings.length} doc updates needed`);
```

With:

```typescript
const findings = env.DEEPSEEK_API_KEY
	? await analyzeWithDeepSeek(allNewItems, env.DEEPSEEK_API_KEY)
	: [];
if (!env.DEEPSEEK_API_KEY) {
	console.warn('DEEPSEEK_API_KEY not set â€” skipping AI analysis');
}
console.log(`AI analysis identified ${findings.length} doc updates needed`);
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 2 â€” FIX services/cron/src/index.ts

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Read the file first. Then:

### 2A â€” Fix Env interface

Replace:

```typescript
export interface Env {
	DB: D1Database;
	ANTHROPIC_API_KEY: string;
	DOC_UPDATE_WEBHOOK?: string;
}
```

With:

```typescript
export interface Env {
	DB: D1Database;
	DEEPSEEK_API_KEY?: string; // Primary AI â€” set via wrangler secret
	DOC_UPDATE_WEBHOOK?: string; // Optional Slack/Discord webhook
}
```

### 2B â€” Fix all three runDocScanner call sites

There are exactly 3 calls to runDocScanner in this file. Change ALL of them:

From: `runDocScanner(env.DB, env.ANTHROPIC_API_KEY)`
To: `runDocScanner(env.DB, env)`

### 2C â€” Add AI provider status to health check

In the health endpoint, replace:

```typescript
const checks: Record<string, boolean> = { db: false };
```

With:

```typescript
const checks: Record<string, boolean> = {
	db: false,
	ai_deepseek: !!env.DEEPSEEK_API_KEY
};
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 3 â€” FIX scripts/apply-updates.mjs

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Read the file first. Then:

### 3A â€” Fix DOC_ROOT path

The script is at `scripts/apply-updates.mjs` inside `cloudflare-foundation-dev/`.
The doc files are at `C:\dev\.cloudflare\` which is ONE LEVEL ABOVE the monorepo.

Current (wrong):

```javascript
const DOC_ROOT = path.resolve(__dirname, '..');
// resolves to: C:\dev\.cloudflare\cloudflare-foundation-dev  â† WRONG
```

Fix:

```javascript
// scripts/ â†’ cloudflare-foundation-dev/ â†’ cloudflare/ (the doc root)
const DOC_ROOT = path.resolve(__dirname, '..', '..');
```

Add startup validation immediately after:

```javascript
// Validate DOC_ROOT is correct
if (!fs.existsSync(path.join(DOC_ROOT, 'BIBLE.md'))) {
	console.error(`\nâŒ DOC_ROOT misconfigured. BIBLE.md not found at:\n   ${DOC_ROOT}`);
	process.exit(1);
}
console.log(`ğŸ“ Doc root: ${DOC_ROOT}`);
```

### 3B â€” Remove the hard exit on missing ANTHROPIC_API_KEY

Remove the entire block:

```javascript
if (!ANTHROPIC_API_KEY) {
	console.error('âŒ ANTHROPIC_API_KEY not set');
	process.exit(1);
}
```

Replace with:

```javascript
const DEEPSEEK_API_KEY = process.env.DEEPSEEK_API_KEY;

if (!DEEPSEEK_API_KEY && !ANTHROPIC_API_KEY) {
	console.warn('âš ï¸  No AI env vars set â€” will apply edits using Claude Code directly');
}
```

### 3C â€” Replace applyFinding's AI call with multi-provider logic

The current `applyFinding` function calls Claude API directly at the bottom.
Replace the entire fetch block (from `const response = await fetch(` to the end
of the `result.summary` block) with this:

```javascript
const result = await callAI(prompt);
if (!result) {
	console.error('   âŒ AI call failed â€” skipping');
	return;
}

for (const [file, content] of Object.entries(result.files ?? {})) {
	const filePath = path.join(DOC_ROOT, file);
	fs.mkdirSync(path.dirname(filePath), { recursive: true });
	fs.writeFileSync(filePath, content, 'utf8');
	console.log(`   âœ… Updated: ${file}`);
}

if (result.summary) {
	console.log(`   ğŸ’¬ ${result.summary}`);
}
```

And add this `callAI` function BEFORE `applyFinding`:

````javascript
/**
 * Apply doc edit using whichever AI is available.
 * Priority: DeepSeek env var â†’ Anthropic env var â†’ error (user must apply manually)
 */
async function callAI(prompt) {
	// 1. Try DeepSeek (fast + cheap, good for structured edits)
	if (DEEPSEEK_API_KEY) {
		try {
			const res = await fetch('https://api.deepseek.com/v1/chat/completions', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					Authorization: `Bearer ${DEEPSEEK_API_KEY}`
				},
				body: JSON.stringify({
					model: 'deepseek-chat',
					max_tokens: 8000,
					temperature: 0.1,
					messages: [
						{
							role: 'system',
							content:
								'You are a documentation editor. Return ONLY valid JSON. No markdown. No explanation.'
						},
						{ role: 'user', content: prompt }
					]
				})
			});
			if (res.ok) {
				const data = await res.json();
				const text = data.choices?.[0]?.message?.content ?? '';
				const clean = text.replace(/```json\n?|\n?```/g, '').trim();
				const parsed = JSON.parse(clean);
				console.log('   ğŸ¤– DeepSeek applied the edit');
				return parsed;
			}
		} catch (e) {
			console.warn(`   âš ï¸  DeepSeek failed: ${e.message}`);
		}
	}

	// 2. Try Anthropic API key if set
	if (ANTHROPIC_API_KEY) {
		try {
			const res = await fetch('https://api.anthropic.com/v1/messages', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					'x-api-key': ANTHROPIC_API_KEY,
					'anthropic-version': '2023-06-01'
				},
				body: JSON.stringify({
					model: 'claude-sonnet-4-20250514',
					max_tokens: 8000,
					system:
						'You are a documentation editor. Return ONLY valid JSON. No markdown. No explanation.',
					messages: [{ role: 'user', content: prompt }]
				})
			});
			if (res.ok) {
				const data = await res.json();
				const text = data.content?.find((b) => b.type === 'text')?.text ?? '';
				const clean = text.replace(/```json\n?|\n?```/g, '').trim();
				const parsed = JSON.parse(clean);
				console.log('   ğŸ¤– Claude (API) applied the edit');
				return parsed;
			}
		} catch (e) {
			console.warn(`   âš ï¸  Claude API failed: ${e.message}`);
		}
	}

	// 3. No provider available â€” print instructions for Claude Code user
	console.log('\n   ğŸ¤– No AI env vars set. Paste this into Claude Code to apply manually:');
	console.log('   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
	console.log(prompt.slice(0, 800) + (prompt.length > 800 ? '\n   [... truncated ...]' : ''));
	console.log('   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
	return null;
}
````

### 3D â€” Fix the gateway URLs (2 places)

In `fetchPendingReports`, change:

```javascript
const res = await fetch(`${GATEWAY_URL}/cron/doc-updates`, { headers });
```

To:

```javascript
const res = await fetch(`${GATEWAY_URL}/api/cron/doc-updates`, { headers });
```

In `markReportApplied`, change:

```javascript
await fetch(`${GATEWAY_URL}/cron/doc-updates/${reportId}`, {
```

To:

```javascript
await fetch(`${GATEWAY_URL}/api/cron/doc-updates/${reportId}`, {
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 4 â€” TYPE CHECK (zero tolerance)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

```bash
cd services/cron && npx tsc --noEmit
cd ../gateway && npx tsc --noEmit
```

Do not proceed until both return exit code 0 with zero errors.

Common errors and exact fixes:

- "analyzeWithClaude is not defined" â†’ old name still referenced, grep and fix
- "Expected 2 args (string)" â†’ runDocScanner signature not updated in index.ts
- "Property ANTHROPIC_API_KEY does not exist on Env" â†’ Env interface not cleaned up
- "Property DEEPSEEK_API_KEY does not exist on ScannerEnv" â†’ interface missing field

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 5 â€” SKIP (D1 tables already confirmed to exist)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Tables doc_scan_state and doc_update_reports already exist in foundation-primary.
Verified via wrangler d1 execute. Move directly to Phase 6.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 6 â€” DEPLOY

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

```bash
# Deploy cron Worker
cd services/cron
npx wrangler deploy --env production
```

Expected output contains: "Deployed foundation-cron-production"

```bash
# Deploy gateway (exposes /api/cron/* endpoints)
cd ../gateway
npx wrangler deploy --env production
```

Expected output contains: "Deployed" with gateway Worker name.

If either deploy fails: read the error, fix it, re-run tsc, redeploy.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 7 â€” VALIDATE

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Run each check and show the full output:

### 7A â€” Health (confirm ai_deepseek: true)

```bash
curl -s https://foundation-cron-production.workers.dev/health | npx fx
```

Expected: `"ai_deepseek": true`

### 7B â€” Trigger scan (THE real test â€” runs all 11 sources + DeepSeek analysis)

```bash
curl -s -X POST https://foundation-cron-production.workers.dev/scan-docs | npx fx
```

Takes 10-30 seconds. Show the full response.
rawItemCount > 0 means sources are working.
If rawItemCount = 0, check Worker logs:

```bash
npx wrangler tail foundation-cron-production --env production
```

### 7C â€” Confirm D1 scan state written

```bash
npx wrangler d1 execute foundation-primary --command \
  "SELECT source, last_seen FROM doc_scan_state ORDER BY source" --remote
```

### 7D â€” Test apply script dry run

```bash
cd ../..
node scripts/apply-updates.mjs --dry-run
```

First line should print: `ğŸ“ Doc root: C:\dev\.cloudflare`
If it prints `cloudflare-foundation-dev` instead â†’ DOC_ROOT fix didn't land.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 8 â€” APPLY KNOWN DOC UPDATES

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Read each file before editing. Make ONLY the changes listed. Touch nothing else.

### 8A â€” C:\dev\.cloudflare\BIBLE.md

THREE separate surgical edits:

EDIT 1 â€” SDK version bump
Find: any occurrence of `v0.3.7` or `agents@0.3.7`
Change to: `v0.6.0` (released Feb 2026)

EDIT 2 â€” RPC transport (add after the agents SDK section, before the next heading)

````markdown
### RPC Transport for MCP â€” Same-Worker (v0.6.0+)

Connect Agent â†’ McpAgent via Durable Object binding instead of HTTP.
Zero network overhead. No OAuth required for internal connections.

**wrangler.jsonc:**

```jsonc
{
	"durable_objects": {
		"bindings": [{ "name": "MY_MCP", "class_name": "MyMcpServer" }]
	}
}
```
````

**Agent code:**

```typescript
await this.addMcpServer('tools', this.env.MY_MCP);
// With user context:
await this.addMcpServer('tools', this.env.MY_MCP, { props: { userId: this.props.userId } });
```

Use HTTP transport only for cross-Worker or external MCP servers.
OAuth is now opt-in â€” simple connections work without it.

````

EDIT 3 â€” Container limits (find and update the limits table or list)
Old values â†’ New values (Feb 2026, 15Ã— increase across the board):
- Memory: 400 GiB â†’ **6 TiB**
- vCPU: 100 â†’ **1,500**
- Disk: 2 TB â†’ **30 TB**

### 8B â€” C:\dev\.cloudflare\patterns\MCP_SERVER.md

Add new section after "When to Use MCP":

```markdown
## RPC Transport â€” Preferred for Same-Worker MCP (v0.6.0+)

When your Agent and McpAgent live in the same Worker, use RPC (DO binding)
instead of HTTP. Benefits: hibernation support, zero latency, no auth setup.

```typescript
// wrangler.jsonc binding
{ "name": "MY_MCP", "class_name": "MyMcpServer" }

// In your Agent
await this.addMcpServer("tools", this.env.MY_MCP);
````

Use HTTP (`url:`) only for external or cross-Worker MCP servers.

````

### 8C â€” C:\dev\.cloudflare\patterns\DURABLE_OBJECTS.md

Find the `deleteAll()` section or storage cleanup section. Add this note:

```typescript
// âš ï¸ Behavior change (compat >= 2026-02-24):
// deleteAll() now atomically deletes BOTH storage AND alarms.
// Previously you needed: await storage.deleteAll() + await storage.deleteAlarm()
await this.ctx.storage.deleteAll(); // handles alarms too, if compat date set
````

### 8D â€” C:\dev\.cloudflare\platform\SERVICES.md

Add these three new entries in the appropriate section:

````markdown
### @cloudflare/codemode v0.1.0 (Feb 2026)

Collapses 2,500+ CF API endpoints into ~1,000 tokens for AI coding agents.

- `createCodeTool()` â€” Workers AI-compatible tool definition
- `DynamicWorkerExecutor` â€” sandboxed, network-isolated code execution
- `npm i @cloudflare/codemode`

### R2 Local Uploads (Open Beta, Feb 2026)

Writes data to nearest R2 location first, replicates globally async.
~75% faster uploads for distributed users. No API change, no extra cost.
Enable: Dashboard â†’ R2 â†’ Bucket â†’ Settings â†’ Local Uploads.

### Sandbox Backups API (Feb 2026)

Point-in-time snapshots of Sandbox state, backed by R2.

```typescript
const id = await sandbox.createBackup();
await sandbox.restoreBackup(id);
```
````

````

### 8E â€” C:\dev\.cloudflare\patterns\MICROFRONTENDS.md

Add new section:

```markdown
## Vinext â€” Next.js Native on Workers (Feb 2026)

Next.js rebuilt on Vite for Cloudflare Workers. Drop-in replacement.
- 4.4Ã— faster builds than @cloudflare/next-on-pages
- 57% smaller bundles
- KV-backed ISR caching
- 94% Next.js API coverage (App Router, Pages Router, RSC, Server Actions)

```bash
npm i vinext
npx vinext deploy
````

Migrate from next-on-pages by swapping the build script in package.json.

````

### 8F â€” C:\dev\.cloudflare\platform\WRANGLER.md

Find the Pipelines section, add:

```markdown
**Wrangler 4.x Pipelines improvements:**
- `wrangler types` now generates TypeScript types for Pipeline bindings
- Simple mode: auto-creates R2 bucket + Data Catalog, minimal config required
- Dashboard: dropped-event metrics per pipeline
````

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 9 â€” ADD npm SCRIPTS TO ROOT package.json

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Read the root package.json. Add these scripts (merge, don't overwrite):

```json
{
	"scripts": {
		"docs:scan": "curl -s -X POST https://foundation-cron-production.workers.dev/scan-docs | npx fx",
		"docs:status": "curl -s https://foundation-cron-production.workers.dev/health | npx fx",
		"docs:pending": "curl -s -H \"Authorization: Bearer $FOUNDATION_API_KEY\" https://gateway.erlvinc.com/api/cron/doc-updates | npx fx",
		"docs:apply": "node scripts/apply-updates.mjs",
		"docs:dry": "node scripts/apply-updates.mjs --dry-run",
		"docs:state": "npx wrangler d1 execute foundation-primary --command \"SELECT source, last_seen FROM doc_scan_state ORDER BY source\" --remote"
	}
}
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## PHASE 10 â€” FINAL CHECKS

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

```bash
# 1. TypeScript clean
cd services/cron && npx tsc --noEmit && echo "CRON OK"
cd ../gateway && npx tsc --noEmit && echo "GATEWAY OK"

# 2. Verify doc edits landed
grep -n "v0\.6\.0" C:\dev\.cloudflare\BIBLE.md
grep -n "RPC Transport" C:\dev\.cloudflare\patterns\MCP_SERVER.md
grep -n "2026-02-24\|deleteAll" C:\dev\.cloudflare\patterns\DURABLE_OBJECTS.md
grep -n "codemode" C:\dev\.cloudflare\platform\SERVICES.md
grep -n "Vinext\|vinext" C:\dev\.cloudflare\patterns\MICROFRONTENDS.md
grep -n "Simple mode" C:\dev\.cloudflare\platform\WRANGLER.md

# 3. Worker health
curl -s https://foundation-cron-production.workers.dev/health | npx fx

# 4. D1 has data
npx wrangler d1 execute foundation-primary --command \
  "SELECT COUNT(*) as sources FROM doc_scan_state" --remote
```

Then output this completion report:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     CLOUDFLARE DOC AUTO-UPDATE SYSTEM â€” DEPLOYMENT COMPLETE         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                      â•‘
â•‘  WORKERS                                                             â•‘
â•‘  â”œâ”€ foundation-cron-production      [DEPLOYED / FAILED]             â•‘
â•‘  â””â”€ foundation-gateway-production   [DEPLOYED / FAILED]             â•‘
â•‘                                                                      â•‘
â•‘  CRON: Doc scanner fires at 06:00 UTC daily                         â•‘
â•‘                                                                      â•‘
â•‘  AI PROVIDER                                                         â•‘
â•‘  â””â”€ DeepSeek (primary)   âœ… DEEPSEEK_API_KEY set via wrangler       â•‘
â•‘     Claude Code (local)  âœ… Used by apply-updates.mjs natively      â•‘
â•‘                                                                      â•‘
â•‘  SOURCES MONITORED (11)                                              â•‘
â•‘  â”œâ”€ npm:  agents, ai-chat, codemode, wrangler, workers-ai-provider  â•‘
â•‘  â”œâ”€ RSS:  CF changelog, CF blog                                      â•‘
â•‘  â”œâ”€ GitHub: cloudflare/agents, cloudflare/workers-sdk               â•‘
â•‘  â””â”€ X:    @CloudflareDev, @Cloudflare                               â•‘
â•‘                                                                      â•‘
â•‘  DOC FILES UPDATED THIS SESSION                                      â•‘
â•‘  â”œâ”€ BIBLE.md                  SDK v0.6.0, RPC, container limits     â•‘
â•‘  â”œâ”€ patterns/MCP_SERVER.md    RPC transport section                 â•‘
â•‘  â”œâ”€ patterns/DURABLE_OBJECTS.md  deleteAll() alarm behavior         â•‘
â•‘  â”œâ”€ platform/SERVICES.md      codemode, R2 local, Sandbox backups  â•‘
â•‘  â”œâ”€ patterns/MICROFRONTENDS.md   Vinext                             â•‘
â•‘  â””â”€ platform/WRANGLER.md      Pipelines typed bindings              â•‘
â•‘                                                                      â•‘
â•‘  DAILY WORKFLOW                                                      â•‘
â•‘  â”œâ”€ Scanner auto-runs 6am UTC                                       â•‘
â•‘  â”œâ”€ /update-docs  â†’  runs from Claude Code terminal                 â•‘
â•‘  â””â”€ pnpm docs:dry â†’  preview without writing files                 â•‘
â•‘                                                                      â•‘
â•‘  YOUR DOCS WILL NEVER BE STALE AGAIN ğŸš€                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## TROUBLESHOOTING

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PROBLEM: rawItemCount: 0 after scan
FIX: npx wrangler tail foundation-cron-production --env production
Look for timeout/fetch errors on individual sources.

PROBLEM: DOC_ROOT prints cloudflare-foundation-dev instead of cloudflare
FIX: DOC_ROOT path.resolve is still 1 level up, not 2. Check Phase 3A.

PROBLEM: "No environment found in configuration with name production" from wrangler d1
FIX: Normal warning â€” the execute still works. The --remote flag is what matters.
You can also omit --env production for d1 execute commands.

PROBLEM: DeepSeek returns malformed JSON
FIX: Add response_format: { type: "json_object" } to the DeepSeek request body
in analyzeWithDeepSeek.

PROBLEM: Gateway /api/cron/doc-updates returns 401
FIX: Pass Authorization header: curl -H "Authorization: Bearer $FOUNDATION_API_KEY"
The gateway token is already in SESSION_KV â€” just set the env var.

PROBLEM: Nitter sources fail
FIX: Expected. Public instances go down. Scanner handles this gracefully with
Promise.allSettled â€” other sources still work.

PROBLEM: Both Workers deploy but health shows ai_deepseek: false
FIX: wrangler secret list --env production should show DEEPSEEK_API_KEY.
If missing: cd services/cron && npx wrangler secret put DEEPSEEK_API_KEY --env production
